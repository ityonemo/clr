const std = @import("std");
const Allocator = std.mem.Allocator;
const Meta = @import("Meta.zig");
const tag = @import("tag.zig");

/// Entity Index - index into the Refinements entity table.
pub const EIdx = u32;

/// Type ID - InternPool index identifying a type for type safety checks.
pub const Tid = u32;

/// Global ID - unique identifier for provenance tracking across function boundaries.
pub const Gid = u32;

/// Sentinel value for uninitialized GIDs. Any access to a refinement with this GID
/// indicates a bug where the refinement wasn't properly added via appendEntity.
pub const INVALID_GID: Gid = std.math.maxInt(Gid);

/// Definition of a global variable for initialization tracking.
/// Generated by codegen and passed to Refinements.init().
pub const GlobalDef = struct {
    /// InternPool index of the pointer to this global (e.g., IP index of &global_point)
    ip_idx: u32,
    /// The type of the global variable.
    /// If the global was declared with `= undefined`, this will be wrapped
    /// in `.{ .ty = .{ .undefined = &inner_type } }` (consistent with store_safe).
    ty: tag.Type,
    /// Source location info - extracted from nav if available.
    /// Use .? to access - crash if unexpectedly null.
    loc: ?SourceLoc,
    children: ChildInfo = .{ .scalar = {} },

    pub const SourceLoc = struct {
        /// Source file path where global is defined
        file: []const u8 = "",
        /// Source line number (0-indexed)
        line: u32 = 0,
        /// Source column number (0-indexed)
        column: u32 = 0,
    };

    pub const ChildInfo = union(enum) {
        scalar: void,
        @"null": void, // special value for optional types that start out null.
        indirect: ?u32, // IP index for indirect targets, null if they start undefined.
        struct_fields: []const ?u32, // IP indices for struct field globals, null if they start undefined.
        union_field: struct {
            active_field_index: ?usize, // which field is active (null if whole union undefined)
            num_fields: usize, // total number of fields
            field_value_ip_idx: ?u32, // IP index for field value, null if undefined
        },
    };
};

pub const Analyte = @import("Analyte.zig");

/// Refinement tracks the type structure of a value along with analysis state.
/// This is like a refinement type - the base type plus predicates/properties.
/// GID is used for anything that needs indirection (pointers, optionals, etc).
pub const Refinement = union(enum) {
    pub const Scalar = struct {
        gid: Gid = INVALID_GID,
        analyte: Analyte = .{},
    };

    pub const Indirected = struct {
        gid: Gid = INVALID_GID,
        analyte: Analyte = .{},
        to: Gid,
    };

    pub const Struct = struct {
        gid: Gid = INVALID_GID,
        /// Analyte for tracking on the whole struct
        analyte: Analyte = .{},
        /// Field refinement GIDs - each field has its own refinement
        /// To obtain the fieldname use field_id = ctx.getFieldId(type_id, field_index) and ctx.getName(field_id)
        fields: []const Gid,
        type_id: Tid,
    };

    pub const Union = struct {
        gid: Gid = INVALID_GID,
        /// Analyte for tracking on the whole union
        analyte: Analyte = .{},
        /// Field refinement GIDs - each field has its own refinement.  Any field
        /// that is null, is NOT active in this variable. Mutable because set_union_tag
        /// needs to activate/deactivate fields.
        /// To obtain the field name use field_id = ctx.getFieldId(type_id, field_index) and ctx.getName(field_id)
        fields: []?Gid,
        type_id: Tid,
    };

    /// AllocatorRef refinement tracks allocator identity for mismatch detection.
    /// The type_id uniquely identifies the allocator type (e.g., PageAllocator vs GPA).
    pub const AllocatorRef = struct {
        gid: Gid = INVALID_GID,
        analyte: Analyte = .{},
        type_id: Tid,
    };

    scalar: Scalar,
    pointer: Indirected,
    optional: Indirected,
    errorunion: Indirected,
    region: Indirected, // unused, for now, will represent slices (maybe)
    @"struct": Struct,
    @"union": Union,
    allocator: AllocatorRef, // tracks allocator identity for mismatch detection
    noreturn: void, // specific return value for error paths.
    unimplemented: void, // this is the result of an operation that is unimplemented but does carry a value.
    void: void, // any instructions that don't store anything.

    /// clobbers one refinement over another.  The dst structure must be identical.
    /// TODO: In some cases, "deeper specification" may be added.
    pub fn clobber_structured(dst: *Refinement, dst_list: *Refinements, src: Refinement, src_list: *Refinements) error{OutOfMemory}!void {
        switch (dst.*) {
            .scalar => {
                if (src != .scalar) std.debug.panic("clobber mismatch: src is .{s} and dst is .scalar", .{@tagName(src)});
                dst.scalar = src.scalar;
            },
            .allocator => {
                if (src != .allocator) std.debug.panic("clobber mismatch: src is .{s} and dst is .allocator", .{@tagName(src)});
                dst.allocator = src.allocator;
            },
            .pointer => try recurse_indirected(dst, dst_list, src, src_list, .pointer),
            .optional => try recurse_indirected(dst, dst_list, src, src_list, .optional),
            .errorunion => try recurse_indirected(dst, dst_list, src, src_list, .errorunion),
            .region => try recurse_indirected(dst, dst_list, src, src_list, .region),
            .@"struct" => recurse_fields(dst, dst_list, src, src_list, .@"struct"),
            .@"union" => recurse_fields(dst, dst_list, src, src_list, .@"union"),
            // following types don't have any metadata associated with them.
            .unimplemented => if (src != .unimplemented) std.debug.panic("clobber mismatch: src is .{s} and dst is .unimplemented", .{@tagName(src)}),
            .void => if (src != .void) std.debug.panic("clobber mismatch: src is .{s} and dst is .void", .{@tagName(src)}),
            .noreturn => if (src != .noreturn) std.debug.panic("clobber mismatch: src is .{s} and dst is .noreturn", .{@tagName(src)}),
        }
    }

    /// clobbers one refinement over another, using GID for destination.
    pub fn clobber_structured_idx(dst_gid: Gid, dst_list: *Refinements, src: Refinement, src_list: *Refinements) error{OutOfMemory}!void {
        const dst = dst_list.at(dst_gid);
        switch (dst.*) {
            .scalar => {
                if (src != .scalar) std.debug.panic("clobber mismatch: src is .{s} and dst is .scalar", .{@tagName(src)});
                dst.scalar = src.scalar;
            },
            .allocator => {
                if (src != .allocator) std.debug.panic("clobber mismatch: src is .{s} and dst is .allocator", .{@tagName(src)});
                dst.allocator = src.allocator;
            },
            .pointer => try recurse_indirected(dst, dst_list, src, src_list, .pointer),
            .optional => try recurse_indirected(dst, dst_list, src, src_list, .optional),
            .errorunion => try recurse_indirected(dst, dst_list, src, src_list, .errorunion),
            .region => try recurse_indirected(dst, dst_list, src, src_list, .region),
            .@"struct" => recurse_fields(dst, dst_list, src, src_list, .@"struct"),
            .@"union" => recurse_fields(dst, dst_list, src, src_list, .@"union"),
            // following types don't have any metadata associated with them.
            .unimplemented => if (src != .unimplemented) std.debug.panic("clobber mismatch: src is .{s} and dst is .unimplemented", .{@tagName(src)}),
            .void => if (src != .void) std.debug.panic("clobber mismatch: src is .{s} and dst is .void", .{@tagName(src)}),
            .noreturn => if (src != .noreturn) std.debug.panic("clobber mismatch: src is .{s} and dst is .noreturn", .{@tagName(src)}),
        }
    }

    fn recurse_indirected(dst: *Refinement, dst_list: *Refinements, src: Refinement, src_list: *Refinements, comptime ref_tag: anytype) error{OutOfMemory}!void {
        if (src != ref_tag) std.debug.panic("clobber mismatch: src is .{s} and dst is .{s}", .{ @tagName(src), @tagName(ref_tag) });
        // copy over analytes.
        @field(dst, @tagName(ref_tag)).analyte = @field(src, @tagName(ref_tag)).analyte;
        const new_dst = dst_list.at(@field(dst, @tagName(ref_tag)).to);
        const new_src = src_list.at(@field(src, @tagName(ref_tag)).to);
        try clobber_structured(new_dst, dst_list, new_src.*, src_list);
    }

    fn recurse_fields(dst: *Refinement, dst_list: *Refinements, src: Refinement, src_list: *Refinements, comptime ref_tag: anytype) void {
        if (src != ref_tag) std.debug.panic("clobber mismatch: src is .{s} and dst is .{s}", .{ @tagName(src), @tagName(ref_tag) });

        const allocator = dst_list.list.allocator;

        // For unions, free old active_metas before overwriting
        if (ref_tag == .@"union") {
            if (@field(dst, @tagName(ref_tag)).analyte.variant_safety) |old_vs| {
                allocator.free(old_vs.active_metas);
            }
        }

        // Copy analyte - deep copy only when crossing between different refinement tables
        // Same table: shallow copy is fine - mutations should be visible
        const new_analyte = if (src_list != dst_list)
            @field(src, @tagName(ref_tag)).analyte.copy(allocator) catch @panic("out of memory")
        else
            @field(src, @tagName(ref_tag)).analyte;
        @field(dst, @tagName(ref_tag)).analyte = new_analyte;

        // Recurse into each field
        const dst_fields = @field(dst, @tagName(ref_tag)).fields;
        const src_fields = @field(src, @tagName(ref_tag)).fields;
        const mutable_dst_fields = @constCast(dst_fields);
        for (mutable_dst_fields, src_fields, 0..) |*dst_field, src_field, i| {
            // if we are in a union, we'll have to unwrap only fields that
            // are non-null, otherwise jump.  For structs no need to unwrap.
            const new_dst_idx, const new_src_idx = new: {
                if (ref_tag == .@"union") {
                    // If src has a field that dst doesn't, need to check if it's active
                    if (src_field != null and dst_field.* == null) {
                        // Check if this field is active in variant_safety
                        if (new_analyte.variant_safety) |vs| {
                            if (vs.active_metas[i] != null) {
                                // Active field in src but not in dst - copy it
                                const new_idx = copyTo(src_list.at(src_field.?).*, src_list, dst_list) catch @panic("out of memory");
                                dst_field.* = new_idx;
                            }
                        }
                        continue;
                    }
                    if (dst_field.* == null or src_field == null) continue;
                    break :new .{ dst_field.*.?, src_field.? };
                } else {
                    break :new .{ dst_field.*, src_field };
                }
            };

            const new_dst = dst_list.at(new_dst_idx);
            const new_src = src_list.at(new_src_idx);
            clobber_structured(new_dst, dst_list, new_src.*, src_list) catch @panic("out of memory");
        }
    }

    /// Cross-table copy: copies refinement from src_list to dst_list.
    /// Uses noalias to assert tables are different.
    /// Follows semideep copy rules - pointers reference same pointee across tables.
    pub fn copyTo(src: Refinement, noalias src_list: *Refinements, noalias dst_list: *Refinements) !Gid {
        return switch (src) {
            .scalar => try dst_list.appendEntity(src),
            .allocator => try dst_list.appendEntity(src),
            .pointer => try src.copyToIndirected(src_list, dst_list, .pointer),
            .optional => try src.copyToIndirected(src_list, dst_list, .optional),
            .errorunion => try src.copyToIndirected(src_list, dst_list, .errorunion),
            .region => try src.copyToIndirected(src_list, dst_list, .region),
            .@"struct" => try src.copyToFields(src_list, dst_list, .@"struct"),
            .@"union" => try src.copyToFields(src_list, dst_list, .@"union"),
            // following types don't have any metadata associated with them.
            .unimplemented => try dst_list.appendEntity(.{ .unimplemented = {} }),
            .void => try dst_list.appendEntity(.{ .void = {} }),
            .noreturn => try dst_list.appendEntity(.{ .noreturn = {} }),
        };
    }

    fn copyToIndirected(src: Refinement, noalias src_list: *Refinements, noalias dst_list: *Refinements, comptime ref_tag: anytype) error{OutOfMemory}!Gid {
        const src_inner_idx = @field(src, @tagName(ref_tag)).to;
        const dst_inner_idx = try copyTo(src_list.at(src_inner_idx).*, src_list, dst_list);
        const to_insert: Refinement = @unionInit(Refinement, @tagName(ref_tag), .{
            .to = dst_inner_idx,
            .analyte = @field(src, @tagName(ref_tag)).analyte,
        });
        return dst_list.appendEntity(to_insert);
    }

    /// Get the GID of this refinement. Unreachable for void/noreturn/unimplemented.
    pub fn getGid(self: Refinement) Gid {
        return switch (self) {
            .void, .noreturn, .unimplemented => unreachable,
            inline else => |data| data.gid,
        };
    }

    fn copyToFields(src: Refinement, noalias src_list: *Refinements, noalias dst_list: *Refinements, comptime ref_tag: anytype) error{OutOfMemory}!Gid {
        const allocator = dst_list.list.allocator;
        const src_data = @field(src, @tagName(ref_tag));
        const src_fields = src_data.fields;

        // Allocate new fields array (same type as source)
        const new_fields = try allocator.alloc(@TypeOf(src_fields[0]), src_fields.len);
        for (src_fields, 0..) |src_field, i| {
            // For unions, fields are optional; for structs, they're not
            const src_field_idx = if (ref_tag == .@"union")
                src_field orelse {
                    new_fields[i] = null;
                    continue;
                }
            else
                src_field;
            const new_idx = try copyTo(src_list.at(src_field_idx).*, src_list, dst_list);
            new_fields[i] = if (ref_tag == .@"union") new_idx else new_idx;
        }

        // Deep copy analyte (handles variant_safety.active_metas slice duplication)
        const new_analyte = try src_data.analyte.copy(allocator);

        return dst_list.appendEntity(@unionInit(Refinement, @tagName(ref_tag), .{
            .analyte = new_analyte,
            .fields = new_fields,
            .type_id = src_data.type_id,
        }));
    }
};

const Refinements = @This();

/// Entity table that stores all Refinement values.
/// Each entity is indexed by GID. Entities can reference other entities
/// via GID (e.g., a pointer entity references its pointee entity).
list: std.array_list.AlignedManaged(Refinement, null),

/// Maps InternPool Nav index to global variable's GID.
/// Used to look up global refinements when they're referenced in AIR.
global_map: std.AutoHashMap(u32, Gid),

/// Cutoff index: all refinements with GID < global_cutoff are global-related.
/// Used by onFinish to determine which allocations are reachable from globals.
/// Set at the end of initWithGlobals, null if no globals.
global_cutoff: ?Gid = null,

pub fn init(allocator: Allocator) Refinements {
    return .{
        .list = std.array_list.AlignedManaged(Refinement, null).init(allocator),
        .global_map = std.AutoHashMap(u32, Gid).init(allocator),
    };
}

/// Initialize refinements with global variable definitions.
/// Creates pointer→value refinement entities for each global and populates the global_map.
/// Global variables are like alloc - they are pointers to storage.
/// Must be called at program start before any function analysis.
pub fn initWithGlobals(allocator: Allocator, ctx: *@import("Context.zig"), comptime global_defs: []const GlobalDef) Refinements {
    var self = Refinements{
        .list = std.array_list.AlignedManaged(Refinement, null).init(allocator),
        .global_map = std.AutoHashMap(u32, Gid).init(allocator),
    };

    // Recursively create all globals - order doesn't matter due to recursion
    // createGlobalEntity uses global_map to track already-created globals
    inline for (global_defs) |def| {
        _ = createGlobalEntity(&self, def, global_defs, ctx, null);
    }

    // Record cutoff - all entities created so far are global-related
    self.global_cutoff = @intCast(self.list.items.len);

    return self;
}

/// Recursively create entity for a global, resolving pointer targets.
/// Uses global_map to track ip_idx→gid for already-created globals.
/// field_info is set when creating field pointer globals to track their origin.
fn createGlobalEntity(
    self: *Refinements,
    comptime def: GlobalDef,
    comptime all_globals: []const GlobalDef,
    ctx: *@import("Context.zig"),
    comptime field_info: ?tag.GlobalFieldInfo,
) Gid {
    // Check if already created (via global_map)
    if (self.global_map.get(def.ip_idx)) |existing_gid| {
        // If we have field_info, we need to apply it even if the global was already created.
        // This happens when a field pointer is registered before its parent struct.
        if (field_info) |finfo| {
            const ptr_ref = self.at(existing_gid);
            if (ptr_ref.* != .pointer) {
                @panic("createGlobalEntity: existing global with field_info is not a pointer");
            }
            ptr_ref.pointer.analyte.fieldparentptr_safety = .{
                .field_index = finfo.field_index,
                .container_type_id = finfo.container_type_id,
            };
        }
        return existing_gid;
    }

    // Check if the type is wrapped in .undefined or .null
    const is_undefined = def.ty.ty == .undefined;
    const is_null = def.ty.ty == .null;

    var pointee_gid: Gid = undefined;

    switch (def.children) {
        .indirect => |target_ip| {
            if (target_ip) |target| {
                // This is a pointer global pointing to another global.
                // First, recursively create the target global.
                const target_def = comptime findGlobalDef(all_globals, target);
                const target_ptr_gid = createGlobalEntity(self, target_def, all_globals, ctx, null);

                // Our value (the pointer) points to the target's value (pointee)
                const target_pointee = self.at(target_ptr_gid).pointer.to;

                // Create our pointer value entity pointing to target's pointee
                pointee_gid = self.appendEntity(.{ .pointer = .{ .to = target_pointee } }) catch @panic("appendEntity failed");
            } else {
                // Pointer starts undefined - create fresh pointee from type
                const pointee_ref = tag.typeToRefinement(def.ty, self) catch @panic("typeToRefinement failed for global");
                pointee_gid = self.appendEntity(pointee_ref) catch @panic("appendEntity failed for global pointee");
            }
        },
        .scalar, .@"null" => {
            // No target - create from type structure
            const pointee_ref = tag.typeToRefinement(def.ty, self) catch @panic("typeToRefinement failed for global");
            pointee_gid = self.appendEntity(pointee_ref) catch @panic("appendEntity failed for global pointee");
        },
        .struct_fields => |field_ip_indices| {
            // Struct global with field pointer children.
            // Get the container type_id from the def's type
            const container_type_id: Tid = comptime blk: {
                const inner_ty = if (def.ty.ty == .undefined) def.ty.ty.undefined else if (def.ty.ty == .null) def.ty.ty.null else &def.ty;
                break :blk inner_ty.id orelse @compileError("struct GlobalDef must have type_id");
            };

            // Create field pointer globals with field_info
            var field_gids: [field_ip_indices.len]Gid = undefined;
            inline for (field_ip_indices, 0..) |field_ip_idx_opt, field_idx| {
                if (field_ip_idx_opt) |field_ip_idx| {
                    const field_def = comptime findGlobalDef(all_globals, field_ip_idx);
                    const finfo = tag.GlobalFieldInfo{
                        .field_index = field_idx,
                        .container_type_id = container_type_id,
                    };
                    const field_ptr_gid = createGlobalEntity(self, field_def, all_globals, ctx, finfo);
                    // Get the pointee from the field pointer
                    field_gids[field_idx] = self.at(field_ptr_gid).pointer.to;
                } else {
                    // Field not linked - create fresh scalar from type
                    field_gids[field_idx] = self.appendEntity(.{ .scalar = .{} }) catch @panic("appendEntity failed");
                }
            }

            // Create struct entity with field GIDs
            const struct_fields = self.list.allocator.alloc(Gid, field_ip_indices.len) catch @panic("OOM for struct fields");
            @memcpy(struct_fields, &field_gids);
            pointee_gid = self.appendEntity(.{ .@"struct" = .{ .fields = struct_fields, .type_id = container_type_id } }) catch @panic("appendEntity failed for struct");
        },
        .union_field => |uaf| {
            const allocator = self.list.allocator;

            // Get the type_id from the def's type (unwrap undefined if needed)
            const type_id: Tid = comptime blk: {
                const inner_ty = if (def.ty.ty == .undefined) def.ty.ty.undefined else if (def.ty.ty == .null) def.ty.ty.null else &def.ty;
                break :blk inner_ty.id orelse @compileError("union GlobalDef must have type_id");
            };

            // Get the union field types from the type
            const union_field_types: []const tag.Type = comptime blk: {
                const inner_ty = if (def.ty.ty == .undefined) def.ty.ty.undefined else if (def.ty.ty == .null) def.ty.ty.null else &def.ty;
                break :blk inner_ty.ty.@"union";
            };

            // field_value_ip_idx == null means the field value is undefined
            const field_value_is_undefined = uaf.field_value_ip_idx == null;

            // Allocate fields array - all null (inactive) initially
            const fields = allocator.alloc(?Gid, uaf.num_fields) catch @panic("OOM");
            @memset(fields, null);

            // If there's an active field, create its entity
            if (uaf.active_field_index) |active_idx| {
                if (active_idx < union_field_types.len) {
                    const field_ref = tag.typeToRefinement(union_field_types[active_idx], self) catch @panic("typeToRefinement failed for union field");
                    const field_gid = self.appendEntity(field_ref) catch @panic("appendEntity failed for union field");
                    fields[active_idx] = field_gid;

                    // Initialize the field's undefined state
                    // (splatInitGlobal for union won't recurse into fields, so we must do it here)
                    const field_loc_info = def.loc orelse GlobalDef.SourceLoc{};
                    const field_loc = tag.GlobalLocation{ .file = field_loc_info.file, .line = field_loc_info.line, .column = field_loc_info.column };
                    tag.splatInitGlobal(self, 0, field_gid, ctx, field_value_is_undefined, false, field_loc, null);
                }
            }

            pointee_gid = self.appendEntity(.{ .@"union" = .{
                .fields = fields,
                .type_id = type_id,
            } }) catch @panic("appendEntity failed for union");
        },
    }

    // Create the global address pointer (always defined - it's a valid global address)
    const ptr_gid = self.appendEntity(.{ .pointer = .{
        .to = pointee_gid,
        .analyte = .{ .undefined_safety = .{ .defined = {} } },
    } }) catch @panic("appendEntity failed for global pointer");

    // Register in global_map
    self.global_map.put(def.ip_idx, ptr_gid) catch {};

    // Dispatch to analysis modules to initialize state
    const loc_info = def.loc orelse GlobalDef.SourceLoc{};
    const loc = tag.GlobalLocation{ .file = loc_info.file, .line = loc_info.line, .column = loc_info.column };
    tag.splatInitGlobal(self, ptr_gid, pointee_gid, ctx, is_undefined, is_null, loc, field_info);

    return ptr_gid;
}

/// Find a GlobalDef by ip_idx in the globals array.
fn findGlobalDef(comptime all_globals: []const GlobalDef, comptime ip_idx: u32) GlobalDef {
    inline for (all_globals) |def| {
        if (def.ip_idx == ip_idx) {
            return def;
        }
    }
    @compileError("target ip_idx not found in all_globals");
}

/// Look up a global's GID by its InternPool index.
/// Works for both direct globals and field pointers (which have their own IP index).
pub fn getGlobal(self: *const Refinements, ip_idx: u32) ?Gid {
    return self.global_map.get(ip_idx);
}

pub fn deinit(self: *Refinements) void {
    const allocator = self.list.allocator;
    // Free any struct and union field allocations
    for (self.list.items) |item| {
        switch (item) {
            inline .@"struct", .@"union" => |data, ref_tag| {
                allocator.free(data.fields);
                // Free variant_safety.active_metas for unions
                if (ref_tag == .@"union") {
                    if (data.analyte.variant_safety) |vs| {
                        allocator.free(vs.active_metas);
                    }
                }
            },
            else => {},
        }
    }
    self.list.deinit();
    self.global_map.deinit();
}

/// Get Refinement by GID. Crashes if GID is out of bounds.
/// Since GID == EIdx at creation and entities don't move, this is O(1).
pub fn at(self: *Refinements, gid: Gid) *Refinement {
    return &self.list.items[gid];
}

/// Find entity by GID. Returns the GID if found, null otherwise.
/// Note: After branch merging, an entity may not exist in this table
/// even if it was created elsewhere with that GID.
/// Since GID == EIdx at creation, this can often be O(1) with a direct lookup.
pub fn findByGid(self: *Refinements, gid: Gid) ?Gid {
    // Fast path: check if gid is a valid index and entity at that index has matching gid
    if (gid < self.list.items.len) {
        switch (self.list.items[gid]) {
            .void, .noreturn, .unimplemented => {},
            inline else => |data| if (data.gid == gid) return gid,
        }
    }
    // Slow path: linear scan (needed after deduplication/merge)
    for (self.list.items, 0..) |ref, idx| {
        switch (ref) {
            .void, .noreturn, .unimplemented => {},
            inline else => |data| if (data.gid == gid) return @intCast(idx),
        }
    }
    return null;
}

/// Append a new entity with the given value and return its GID.
/// GID is automatically assigned as the entity's index (GID = EIdx at creation).
pub fn appendEntity(self: *Refinements, value: Refinement) !Gid {
    const idx: Gid = @intCast(self.list.items.len);
    var entity = value;
    // GID = EIdx at creation time (stable identity across clones/merges)
    switch (entity) {
        .void, .noreturn, .unimplemented => {},
        inline else => |*data| data.gid = idx,
    }
    try self.list.append(entity);
    return idx;
}

/// Append a new entity with the given value, assigning a new global ID from the counter.
/// DEPRECATED: Use appendEntity instead, which auto-assigns GID = EIdx.
pub fn appendEntityWithGid(self: *Refinements, value: Refinement, gid_counter: *Gid) !Gid {
    const idx: Gid = @intCast(self.list.items.len);
    var entity = value;
    const gid = gid_counter.*;
    gid_counter.* += 1;
    switch (entity) {
        .void, .noreturn, .unimplemented => {},
        inline else => |*data| data.gid = gid,
    }
    try self.list.append(entity);
    return idx;
}

/// Deep clone the entire refinements table.
/// GID references remain valid because indices are preserved.
/// Struct and union field slices are deep copied so each refinements list owns its own memory.
pub fn clone(self: *Refinements, allocator: Allocator) !Refinements {
    var new = Refinements.init(allocator);
    try new.list.ensureTotalCapacity(self.list.items.len);
    for (self.list.items) |item| {
        switch (item) {
            inline .@"struct", .@"union" => |data, ref_tag| {
                // Deep copy fields
                const new_fields = try allocator.alloc(@TypeOf(data.fields[0]), data.fields.len);
                @memcpy(new_fields, data.fields);
                // Deep copy analyte (handles variant_safety.active_metas slice duplication)
                const new_analyte = try data.analyte.copy(allocator);
                try new.list.append(@unionInit(Refinement, @tagName(ref_tag), .{
                    .analyte = new_analyte,
                    .fields = new_fields,
                    .type_id = data.type_id,
                }));
            },
            else => try new.list.append(item),
        }
    }
    // Copy global_map - GIDs are stable so we can just copy entries
    var it = self.global_map.iterator();
    while (it.next()) |entry| {
        try new.global_map.put(entry.key_ptr.*, entry.value_ptr.*);
    }
    // Copy global_cutoff
    new.global_cutoff = self.global_cutoff;
    return new;
}

/// Deep copy a Refinement value, allocating new memory for struct/union fields.
/// Use this when copying a refinement to another slot to avoid double-free.
pub fn deepCopyValue(self: *Refinements, src: Refinement) !Refinement {
    const allocator = self.list.allocator;
    return switch (src) {
        inline .@"struct", .@"union" => |data, ref_tag| blk: {
            // Deep copy fields
            const new_fields = try allocator.alloc(@TypeOf(data.fields[0]), data.fields.len);
            @memcpy(new_fields, data.fields);
            // Deep copy analyte (handles variant_safety.active_metas slice duplication)
            const new_analyte = try data.analyte.copy(allocator);
            break :blk @unionInit(Refinement, @tagName(ref_tag), .{
                .analyte = new_analyte,
                .fields = new_fields,
                .type_id = data.type_id,
            });
        },
        else => src, // Non-container types can be shallow copied
    };
}

/// Semideep copy within same table: creates new entity, copying values but sharing pointer targets.
/// For struct/union, recursively copies value fields, but pointer fields reference same pointee.
/// Deep copies analyte via analyte.copy().
pub fn semideepCopy(self: *Refinements, src_gid: Gid) error{OutOfMemory}!Gid {
    const src = self.at(src_gid).*;
    return self.semideepCopyRefinement(src);
}

fn semideepCopyRefinement(self: *Refinements, src: Refinement) error{OutOfMemory}!Gid {
    const allocator = self.list.allocator;
    return switch (src) {
        // Scalars and allocators: copy to new entity
        .scalar => try self.appendEntity(src),
        .allocator => try self.appendEntity(src),

        // Pointers: new pointer entity, same .to (reference existing pointee)
        .pointer => |p| try self.appendEntity(.{
            .pointer = .{
                .analyte = p.analyte,
                .to = p.to, // Same pointee - this is the "boundary"
            },
        }),

        // Optionals/errorunions: recurse into payload (semideep copy the inner value)
        .optional => |o| blk: {
            const new_inner = try self.semideepCopy(o.to);
            break :blk try self.appendEntity(.{ .optional = .{
                .analyte = o.analyte,
                .to = new_inner,
            } });
        },
        .errorunion => |e| blk: {
            const new_inner = try self.semideepCopy(e.to);
            break :blk try self.appendEntity(.{ .errorunion = .{
                .analyte = e.analyte,
                .to = new_inner,
            } });
        },

        // Structs: new struct with semideep copied fields
        .@"struct" => |s| blk: {
            const new_fields = try allocator.alloc(Gid, s.fields.len);
            for (s.fields, 0..) |field_idx, i| {
                new_fields[i] = try self.semideepCopy(field_idx);
            }
            break :blk try self.appendEntity(.{ .@"struct" = .{
                .analyte = s.analyte,
                .fields = new_fields,
                .type_id = s.type_id,
            } });
        },

        // Unions: new union with semideep copied active fields
        .@"union" => |u| blk: {
            const new_fields = try allocator.alloc(?Gid, u.fields.len);
            for (u.fields, 0..) |field_idx_opt, i| {
                new_fields[i] = if (field_idx_opt) |field_idx|
                    try self.semideepCopy(field_idx)
                else
                    null;
            }
            // Deep copy analyte (handles variant_safety.active_metas slice duplication)
            const new_analyte = try u.analyte.copy(allocator);
            break :blk try self.appendEntity(.{ .@"union" = .{
                .analyte = new_analyte,
                .fields = new_fields,
                .type_id = u.type_id,
            } });
        },

        .region => |r| blk: {
            const new_inner = try self.semideepCopy(r.to);
            break :blk try self.appendEntity(.{ .region = .{
                .analyte = r.analyte,
                .to = new_inner,
            } });
        },

        // Simple types: just copy
        .unimplemented => try self.appendEntity(.{ .unimplemented = {} }),
        .void => try self.appendEntity(.{ .void = {} }),
        .noreturn => try self.appendEntity(.{ .noreturn = {} }),
    };
}

/// Create pointer entity referencing existing entity (for struct_field_ptr, bitcast on pointer, etc.)
pub fn createPointerTo(self: *Refinements, pointee_gid: Gid, analyte: Analyte) !Gid {
    return self.appendEntity(.{ .pointer = .{
        .analyte = analyte,
        .to = pointee_gid,
    } });
}

const undefined_analysis = @import("analysis/undefined_safety.zig");
const memory_safety_analysis = @import("analysis/memory_safety.zig");
const null_safety_analysis = @import("analysis/null_safety.zig");
const variant_safety_analysis = @import("analysis/variant_safety.zig");

pub fn testValid(self: *Refinements) void {
    for (self.list.items, 0..) |refinement, i| {
        undefined_analysis.testValid(refinement, i);
        memory_safety_analysis.testValid(refinement);
        null_safety_analysis.testValid(refinement);
        variant_safety_analysis.testValid(refinement);
    }
}

test "initWithGlobals sets null_safety for null optional global" {
    const Context = @import("Context.zig");
    const allocator = std.testing.allocator;

    var buf: [4096]u8 = undefined;
    var discarding = std.Io.Writer.Discarding.init(&buf);
    var ctx = Context.init(allocator, &discarding.writer);
    defer ctx.deinit();

    // Create global_defs with a null optional
    const inner_scalar: tag.Type = .{ .ty = .{ .scalar = {} } };
    const optional_type: tag.Type = .{ .ty = .{ .optional = &inner_scalar } };
    const null_type: tag.Type = .{ .ty = .{ .null = &optional_type } };

    const global_defs = [_]GlobalDef{
        .{ .ip_idx = 100, .ty = null_type, .loc = .{ .file = "test.zig", .line = 1, .column = 1 } },
    };

    var refinements = initWithGlobals(allocator, &ctx, &global_defs);
    defer refinements.deinit();

    // Get the global pointer GID
    const ptr_gid = refinements.getGlobal(100).?;
    const ptr = refinements.at(ptr_gid);

    // Follow pointer to pointee (the optional)
    try std.testing.expect(ptr.* == .pointer);
    const opt_gid = ptr.pointer.to;
    const opt = refinements.at(opt_gid);

    // Verify it's an optional with null_safety set to .@"null"
    try std.testing.expect(opt.* == .optional);
    const ns = opt.optional.analyte.null_safety.?;
    try std.testing.expect(ns == .null);
}

test "initWithGlobals sets undefined_safety for undefined union global" {
    const Context = @import("Context.zig");
    const allocator = std.testing.allocator;

    var buf: [4096]u8 = undefined;
    var discarding = std.Io.Writer.Discarding.init(&buf);
    var ctx = Context.init(allocator, &discarding.writer);
    defer ctx.deinit();

    // Create global_defs with an undefined union
    const inner_scalar: tag.Type = .{ .ty = .{ .scalar = {} } };
    const union_type: tag.Type = .{ .id = 5120, .ty = .{ .@"union" = &.{ inner_scalar, inner_scalar } } };
    const undefined_union_type: tag.Type = .{ .ty = .{ .undefined = &union_type } };

    const global_defs = [_]GlobalDef{
        .{ .ip_idx = 100, .ty = undefined_union_type, .loc = .{ .file = "test.zig", .line = 1, .column = 1 }, .children = .{ .union_field = .{ .active_field_index = null, .num_fields = 2, .field_value_ip_idx = null } } },
    };

    var refinements = initWithGlobals(allocator, &ctx, &global_defs);
    defer refinements.deinit();

    // Get the global pointer GID
    const ptr_gid = refinements.getGlobal(100).?;
    const ptr = refinements.at(ptr_gid);

    // Follow pointer to pointee (the union)
    try std.testing.expect(ptr.* == .pointer);
    const union_gid = ptr.pointer.to;
    const u = refinements.at(union_gid);

    // Verify it's a union with undefined_safety set to .undefined
    try std.testing.expect(u.* == .@"union");
    const us = u.@"union".analyte.undefined_safety.?;
    try std.testing.expect(us == .undefined);

    // Also verify fields are all null (no active field)
    try std.testing.expect(u.@"union".fields[0] == null);
    try std.testing.expect(u.@"union".fields[1] == null);
}

test "semideepCopy preserves union undefined_safety" {
    const Context = @import("Context.zig");
    const allocator = std.testing.allocator;

    var buf: [4096]u8 = undefined;
    var discarding = std.Io.Writer.Discarding.init(&buf);
    var ctx = Context.init(allocator, &discarding.writer);
    defer ctx.deinit();

    // Create global_defs with an undefined union
    const inner_scalar: tag.Type = .{ .ty = .{ .scalar = {} } };
    const union_type: tag.Type = .{ .id = 5120, .ty = .{ .@"union" = &.{ inner_scalar, inner_scalar } } };
    const undefined_union_type: tag.Type = .{ .ty = .{ .undefined = &union_type } };

    const global_defs = [_]GlobalDef{
        .{ .ip_idx = 100, .ty = undefined_union_type, .loc = .{ .file = "test.zig", .line = 1, .column = 1 }, .children = .{ .union_field = .{ .active_field_index = null, .num_fields = 2, .field_value_ip_idx = null } } },
    };

    var refinements = initWithGlobals(allocator, &ctx, &global_defs);
    defer refinements.deinit();

    // Get the global pointer and union
    const ptr_gid = refinements.getGlobal(100).?;
    const union_gid = refinements.at(ptr_gid).pointer.to;

    // Semideep copy the union (simulating a load)
    const copy_gid = try refinements.semideepCopy(union_gid);
    const copy = refinements.at(copy_gid);

    // Verify the copy is a union with undefined_safety preserved
    try std.testing.expect(copy.* == .@"union");
    const us = copy.@"union".analyte.undefined_safety.?;
    try std.testing.expect(us == .undefined);

    // Also verify fields are all null (no active field)
    try std.testing.expect(copy.@"union".fields[0] == null);
    try std.testing.expect(copy.@"union".fields[1] == null);
}
